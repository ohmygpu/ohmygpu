[workspace]
resolver = "2"
members = [
    "crates/core",
    "crates/runtimes/runtime_api",
    "crates/runtimes/runtime_candle",
    "daemon",
    "cli",
]

[workspace.package]
version = "0.1.0"
edition = "2021"
license = "Apache-2.0"
repository = "https://github.com/ohmygpu/ohmygpu"

[workspace.dependencies]
# Internal crates
ohmygpu_core = { path = "crates/core" }
ohmygpu_runtime_api = { path = "crates/runtimes/runtime_api" }
ohmygpu_runtime_candle = { path = "crates/runtimes/runtime_candle" }
ohmygpu_daemon = { path = "daemon" }

# Async runtime
tokio = { version = "1", features = ["full"] }

# HTTP
reqwest = { version = "0.12", features = ["json", "stream"] }
axum = { version = "0.7", features = ["ws"] }
tower = "0.4"
tower-http = { version = "0.5", features = ["cors", "trace"] }

# Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"

# Error handling
anyhow = "1"
thiserror = "2"

# Async utilities
async-trait = "0.1"
futures-util = "0.3"
async-stream = "0.3"

# CLI
clap = { version = "4", features = ["derive"] }

# TUI
ratatui = "0.29"
crossterm = "0.28"

# Progress and utilities
indicatif = "0.17"
directories = "5"
chrono = { version = "0.4", features = ["serde"] }

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Config
toml = "0.8"

# Candle inference (with Metal/CUDA support)
candle-core = "0.8"
candle-nn = "0.8"
candle-transformers = "0.8"
tokenizers = "0.20"
hf-hub = "0.3"

# Self-update
self_update = { version = "0.39", features = ["archive-tar", "compression-flate2"] }
